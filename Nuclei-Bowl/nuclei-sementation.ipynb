{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-07T19:54:50.079154Z","iopub.execute_input":"2022-07-07T19:54:50.079836Z","iopub.status.idle":"2022-07-07T19:54:50.118813Z","shell.execute_reply.started":"2022-07-07T19:54:50.079693Z","shell.execute_reply":"2022-07-07T19:54:50.117690Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Libraries\nimport tensorflow as tf\nimport zipfile\nimport numpy as np\nimport random\nimport os\nfrom tqdm import tqdm\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:54:50.120910Z","iopub.execute_input":"2022-07-07T19:54:50.121582Z","iopub.status.idle":"2022-07-07T19:55:00.140184Z","shell.execute_reply.started":"2022-07-07T19:54:50.121525Z","shell.execute_reply":"2022-07-07T19:55:00.138960Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# set the seed and set a path to data folder\nSEED = 42\nnp.random.seed = SEED\n\nUNZIP_PATH = '../input/data-science-bowl-2018/'\nTRAIN_PATH = './train/'\nTEST_PATH = './test/'\n\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:55:00.141768Z","iopub.execute_input":"2022-07-07T19:55:00.142310Z","iopub.status.idle":"2022-07-07T19:55:00.147993Z","shell.execute_reply.started":"2022-07-07T19:55:00.142280Z","shell.execute_reply":"2022-07-07T19:55:00.146932Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Unzip data\nwith zipfile.ZipFile(UNZIP_PATH+'stage1_train.zip', 'r') as zip_ref:\n    zip_ref.extractall('./train')\n    \nwith zipfile.ZipFile(UNZIP_PATH+'stage1_test.zip', 'r') as zip_ref:\n    zip_ref.extractall('./test')","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:55:00.150414Z","iopub.execute_input":"2022-07-07T19:55:00.150747Z","iopub.status.idle":"2022-07-07T19:55:05.479483Z","shell.execute_reply.started":"2022-07-07T19:55:00.150717Z","shell.execute_reply":"2022-07-07T19:55:05.478630Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# get list of all subfolders\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:55:05.480678Z","iopub.execute_input":"2022-07-07T19:55:05.481448Z","iopub.status.idle":"2022-07-07T19:55:05.488604Z","shell.execute_reply.started":"2022-07-07T19:55:05.481411Z","shell.execute_reply":"2022-07-07T19:55:05.487774Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# define placeholders with numpy array of zeroz\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:55:05.490772Z","iopub.execute_input":"2022-07-07T19:55:05.492016Z","iopub.status.idle":"2022-07-07T19:55:05.519189Z","shell.execute_reply.started":"2022-07-07T19:55:05.491967Z","shell.execute_reply":"2022-07-07T19:55:05.518276Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('Resizing training images and masks')\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n    path = TRAIN_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img  #Fill empty X_train with values from img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)  \n            \n    Y_train[n] = mask   \n\n# test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Resizing test images') \nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!') ","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:55:05.521046Z","iopub.execute_input":"2022-07-07T19:55:05.522485Z","iopub.status.idle":"2022-07-07T20:02:16.633977Z","shell.execute_reply.started":"2022-07-07T19:55:05.522431Z","shell.execute_reply":"2022-07-07T20:02:16.632742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nimage_x = random.randint(0, len(train_ids))\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(Y_train[image_x]))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T20:08:48.108881Z","iopub.execute_input":"2022-07-07T20:08:48.109271Z","iopub.status.idle":"2022-07-07T20:08:48.474602Z","shell.execute_reply.started":"2022-07-07T20:08:48.109238Z","shell.execute_reply":"2022-07-07T20:08:48.473525Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\ns = tf.keras.layers.Lambda(lambda x: x/255.0)(inputs) # normalization\n\n# Contraction path\nc1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(s) # start with normal distributed weights\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c1)\np1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n\nc2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c2)\np2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n\nc3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c3)\np3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n\nc4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c4)\np4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n\nc5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c5)\n\n# Expansive path\nu6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides = (2,2), padding = \"same\")(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c6)\n\nu7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides = (2,2), padding = \"same\")(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c7)\n\nu8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides = (2,2), padding = \"same\")(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c8)\n\nu9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides = (2,2), padding = \"same\")(c8)\nu9 = tf.keras.layers.concatenate([u9, c1])\nc9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer = \"he_normal\", padding = \"same\")(c9)\n\noutputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c9)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T20:02:17.089209Z","iopub.execute_input":"2022-07-07T20:02:17.089774Z","iopub.status.idle":"2022-07-07T20:02:18.706877Z","shell.execute_reply.started":"2022-07-07T20:02:17.089733Z","shell.execute_reply":"2022-07-07T20:02:18.705748Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # Callbacks\n# checkpoiter = tf.keras.callbacks.ModelCheckpoint('model.h5', verbose = 1, save_best_only = True)\n# callbacks = [\n#     tf.keras.callbacks.EarlyStopping(patience = 5, monitor = 'val_loss'),\n#     tf.keras.callbacks.TensorBoard(log_dir = 'logs')\n#             ]","metadata":{"execution":{"iopub.status.busy":"2022-07-07T20:02:18.708215Z","iopub.execute_input":"2022-07-07T20:02:18.708638Z","iopub.status.idle":"2022-07-07T20:02:18.714028Z","shell.execute_reply.started":"2022-07-07T20:02:18.708604Z","shell.execute_reply":"2022-07-07T20:02:18.712950Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"results = model.fit(\n    X_train, \n    Y_train, \n    validation_split = 0.1, \n    batch_size = 16, \n    epochs = 25)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T20:02:18.716982Z","iopub.execute_input":"2022-07-07T20:02:18.717445Z","iopub.status.idle":"2022-07-07T20:04:21.907187Z","shell.execute_reply.started":"2022-07-07T20:02:18.717401Z","shell.execute_reply":"2022-07-07T20:04:21.905320Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}